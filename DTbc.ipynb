{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82d148b",
   "metadata": {},
   "source": [
    "Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a546d8-e945-4927-a003-a51872d12a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The order of importing libraries are according to the sequence of steps taken in our work.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26097886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(\"A1_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data types of each column\n",
    "column_types = df.dtypes\n",
    "\n",
    "# Print the data types\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_data(df):\n",
    "    # Check for missing values\n",
    "    print('Missing values in the DataFrame:\\n', df.isnull().sum(),'\\n')\n",
    "    # Check for duplicates\n",
    "    print('Number of duplicated rows in the DataFrame:\\n', df.duplicated().sum(),'\\n')\n",
    "    # Check for unique values\n",
    "    print('Number of unique values in each column of the DataFrame:\\n', df.nunique(),'\\n')\n",
    "    # Check for out of bound value\n",
    "    stats=df.describe()\n",
    "    print(stats)\n",
    "    \n",
    "    \n",
    "    # Set the figure size to make the plot wider\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    #Create a boxplot for each numeric column\n",
    "    ax = df.boxplot()\n",
    "      \n",
    "    # Set the rotation angle for x-axis labels\n",
    "    plt.xticks(rotation=45)  # You can adjust the rotation angle as needed\n",
    "\n",
    "   # Show the plot\n",
    "    plt.show()\n",
    "identify_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa40b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the month from the 'Date' column\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "# Columns for imputation\n",
    "numerical_columns_to_impute = ['Minimum_Temperature', 'Maximum_Temperature', 'Wind_Speed_AM', 'Wind_Speed_PM', \n",
    "                               'Rainfall_Amount', 'Max_WindGust_Speed']\n",
    "categorical_columns_to_impute = ['Wind_Direction_AM', 'Wind_Direction_PM', 'Max_WindGust_Direction', 'Climate', 'Season', \n",
    "                                 'Significant_Rainfall']\n",
    "\n",
    "# Impute numerical columns with monthly median\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "for col in numerical_columns_to_impute:\n",
    "    df[col] = df.groupby('Month')[col].transform(lambda x: median_imputer.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "# Impute categorical columns with monthly mode\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "for col in categorical_columns_to_impute:\n",
    "    df[col] = df.groupby('Month')[col].transform(lambda x: mode_imputer.fit_transform(x.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "# Drop the 'Month' column not needed anymore\n",
    "df.drop('Month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4d86f",
   "metadata": {},
   "source": [
    "Further Data Preparation for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to one-hot encode\n",
    "categorical_columns = ['City_Name', 'City_State', 'Climate', 'Season', 'Significant_Rainfall',\n",
    "                       'Wind_Direction_AM', 'Wind_Direction_PM', 'Max_WindGust_Direction']\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Print the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of categorical columns to one-hot encode\n",
    "categorical_columns = ['City_Name', 'City_State', 'Climate', 'Season', 'Significant_Rainfall',\n",
    "                       'Wind_Direction_AM', 'Wind_Direction_PM', 'Max_WindGust_Direction']\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Print the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_encoded.drop('Burn_Tomorrow', axis=1)\n",
    "y = df_encoded['Burn_Tomorrow']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d48110",
   "metadata": {},
   "source": [
    "Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daab3c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "# Exclude the 'Date' column from X\n",
    "X_scaled = scaler.fit_transform(X.drop('Date', axis=1))\n",
    "\n",
    "# Import the SMOTE class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Instantiate SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the features and target variables\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Print the shape of the resampled data\n",
    "print(\"Shape of X_resampled:\", X_resampled.shape)\n",
    "print(\"Shape of y_resampled:\", y_resampled.shape)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of train and test sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697cd7e",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94925139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Rank features by importance\n",
    "feature_ranking = sorted(range(len(feature_importances)), key=lambda i: feature_importances[i], reverse=True)\n",
    "\n",
    "# Select top N features (e.g., top 10)\n",
    "top_n_features = feature_ranking[:10]\n",
    "\n",
    "# Create a new dataset with the selected features\n",
    "X_train_selected = X_train[:, top_n_features]\n",
    "X_test_selected = X_test[:, top_n_features]\n",
    "\n",
    "# Print the shape of train_selected and test_selected sets\n",
    "print(\"Shape of X_train_selected:\", X_train_selected.shape)\n",
    "print(\"Shape of X_test_selected:\", X_test_selected.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68860faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of feature names in the original dataset\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Get the names of the top selected features\n",
    "selected_feature_names = [feature_names[i] for i in top_n_features]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print('selected_feature_names:\\n', selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e1fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Create a Decision Tree Classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Train the Decision Tree Classifier on the selected features\n",
    "decision_tree_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 3: Perform cross-validation on the Decision Tree Classifier\n",
    "scores = cross_val_score(decision_tree_classifier, X_train_selected, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of the cross-validation scores\n",
    "mean_score = scores.mean()\n",
    "std_score = scores.std()\n",
    "\n",
    "# Print the mean accuracy and standard deviation\n",
    "print(\"Mean accuracy:\", mean_score)\n",
    "print(\"Standard deviation:\", std_score)\n",
    "\n",
    "# Step 4: Make Predictions\n",
    "y_pred_dt = decision_tree_classifier.predict(X_test_selected)\n",
    "\n",
    "# Step 5: Evaluate the Decision Tree Classifier\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "classification_report_str = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "# Print the accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d135f624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
